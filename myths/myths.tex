
\section{Myths on PiP}

\subsection*{I fail to distinguish what PiP performs from shared
  memory.}\label{sec:shared-memory-myth} 

The shared memory model enables access to the data of the other
process. The XPMEM\footnote{\url{https://github.com/hpc/xpmem}} shared
memory mode facilitates the sharing of any 
existing memory region with the other process, in contrast to the
POSIX shared memory paradigm, which only permits the sharing of newly
allocated memory regions. I use the term "shared address space model"
instead of "shared memory model" to describe PiP's technique for
mapping memory areas. The shared address space and shared memory
appear to be the same in order to access the data owned by the other.

However, the mechanisms behind the two memory theories differ
greatly. To request shared memory, one must issue a system call to the
OS kernel. The system calls that alter the memory mapping are rather
expensive. When the addresses of the data are known, a PiP job can
access any data owned by the others without making an expensive system
call because PiP tasks, on the other hand, are mapped to a single
memory address.

If the shared data are allocated dynamically or are distributed over
the address space and difficult to pack into a memory area, the shared
address space solution is advantageous.

\subsubsection*{A serious security risk might arise when many programs
  share the same address}\label{sec:security-issue} 

A serious security risk might arise when many programs share the same address. 
Programs that share an address space can run thanks to
PiP. Facilitating efficient information sharing between programs is
the main goal here. If there is no interaction between them, running
them in the PiP environment is useless.  

Programs for communication fundamentally have the same outcome. Even
in the most straightforward case, if two programs are connected by a
Linux/Unix pipe and one of the programs crashes, the other programs
also crash after receiving the \linuxdef{SIGPIPE}
signal. Communicating processes agree on when and how to communicate with
others. The PiP scenario is not exceptional.

\subsubsection*{Sharing address space makes debugging difficult}

It is true that if one operation in a PiP environment destroys data
that belongs to another, the consequences could be disastrous. If done
maliciously, this cannot be prevented (see also above). It may be more
difficult to debug the destruction if a software flaw caused it than
the multi-process paradigm. There are two things to note in this
situation: 1) the increased risk of actually destroying data rather
than accessing an invalid memory location (\linuxdef{SIGSEGV}), and 2)
the existence of numerous execution entities.

For the earlier point, the \term{ASLR} can be helpful. The bug's phenomena
can change over time if \term{ASLR} is enabled. With the multi-thread
example, the last point's situation is essentially the same.  

Anyway, I haven't had any problems with issues based on this scenario
yet.

\subsubsection*{My program does not have any static variables and I do
  not need PiP.}

Programs can be written without using static variables. However,
Glibc's routines use a lot of static variables. Some of the Glibc
functions may be used by your runtime system. Therefore, it is
generally quite difficult to write programs without using any static
variables.

\subsubsection*{PiP may consume more memory than the other execution
  models}

A single address space is used to map the memory segments of active
PiP activities, as shown in Listing 3.4. For instance,
Listing~\ref{out:maps} only displays the memory segments connected to
Glibc ({\tt libc-2.28.so}), 
which is loaded three (3) times in this case to operate one PiP root
and two PiP tasks, each of which depends on Glibc. A memory map of
{\tt libc-2.28.so} is contained in each segment set. The same file is
used to map all three segment sets, and only one set uses the same
amount of RAM.

Each address space of a process in the multi-process paradigm only has
one {\tt libc-2.28.so} segment set, although another process also uses the
same memory mapping as Glibc. Therefore, practically speaking, the
memory needed to run PiP tasks is comparable to the memory needed to
operate multiple processes. However, regardless of the number of
threads, the multi-thread model only has one variable segment that is
shared by all of the threads. Additionally, performing PiP jobs
requires more memory than running multiple threads does.

\subsubsection*{There must be some hidden overhead for running PiP
  programs}

As of now, one overhead that is greater than the multi-process model
is known. System calls for address space change, such
\linuxfunc{mmap()} and \linuxfunc{brk()}. This is because any change
to an address space inside the OS 
kernel must be locked, and lock contention causes more overhead. The
scenario is the same when using the multi-thread model, and while
\linuxfunc{mmap()} has a higher overhead than the multi-process model,
it is nearly identical when using the multi-thread model. Up to now,
no additional overhead in PiP has been identified.
